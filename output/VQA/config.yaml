ann_root: annotation
batch_size_test: 32
batch_size_train: 16
image_size: 480
inference: rank
init_lr: 2e-05
k_test: 128
max_epoch: 10
min_lr: 0
pretrained: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_vqa_capfilt_large.pth
train_files: [vqa_train, vqa_val]
vg_root: ''
vit: base
vit_ckpt_layer: 0
vit_grad_ckpt: false
vqa_root: /export/share/datasets/vision/VQA/Images/mscoco/
weight_decay: 0.05
